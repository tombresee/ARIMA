{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######  ![air_revenue](air_revenue.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.11.0-py2.py3-none-any.whl (13.1 MB)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in c:\\users\\tbresee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (from plotly) (1.15.0)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11434 sha256=3a42b9cb62cdec5cf391398bcc2014e30958557d88a12ce05336bd526f7926c8\n",
      "  Stored in directory: c:\\users\\tbresee\\appdata\\local\\pip\\cache\\wheels\\c4\\a7\\48\\0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.11.0 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series for Air revenue passenger prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under this project scope we will forecast monthly air passenger revenue using time series techniques. <br>\n",
    "Time series is useful method in machine learning when we need to forecast a value given a time component: an information about the time period previous values were recorded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**: series sourced form \"Federal reserve economic data\" via Quandl API:<br>\n",
    "https://www.quandl.com/data/FRED/AIRRPMTSI-Air-Revenue-Passenger-Miles. <br>\n",
    "Observations include *monthly* air revenue starting from 2000 to present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quandl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c982d674eccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquandl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'quandl'"
     ]
    }
   ],
   "source": [
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quandl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b99df4bd2ff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquandl\u001b[0m \u001b[1;31m# use quandl linbrary to retreive the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwill\u001b[0m \u001b[0muse\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mmanipulation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcalculus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwork\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'quandl'"
     ]
    }
   ],
   "source": [
    "# import quandl # use quandl linbrary to retreive the data \n",
    "\n",
    "\"\"\"\n",
    "- will use pandas and numpy for data manipulation and calculus\n",
    "- import datetime to work with datetime type\n",
    "- use Series library to work with time series \n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd          \n",
    "import numpy as np           \n",
    "from datetime import datetime    \n",
    "from pandas import Series  \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%pylab inline\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# will ignore the warnings\n",
    "import warnings                 \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- to work with statistical models we statsmodels.api and stats module from scipy\n",
    "- use itertools and seasonal_decompose for data preparation and model building\n",
    "- to plot PACF/ACF chart use tsaplots graphic module\n",
    "\n",
    "\"\"\"\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.api import Holt\n",
    "\n",
    "import itertools\n",
    "from itertools import product\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose # perform seasonal decomposition\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0aff6ad343b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdownload_plotlyjs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- visualize results using plotly library, connected to current notebook\n",
    "\n",
    "\"\"\"\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install quandl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retreive data from source, we opearte .get() function, using token and dataset reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quandl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-323bb78bc1d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mauthtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"XXXXXX\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquandl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FRED/AIRRPMTSI\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauthtoken\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauthtoken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'quandl' is not defined"
     ]
    }
   ],
   "source": [
    "authtoken = \"XXXXXX\"\n",
    "df = quandl.get(\"FRED/AIRRPMTSI\", authtoken=authtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-bc340db5f780>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# show how the data looks like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head() # show how the data looks like "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice it's not necessary to use the entire time series. To provide precise analysis we are going to use date range from 2010-01-01 to 2018-09-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2d42b149d0a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'2010-01-01'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'2018-09-01'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# plot values from range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# setting up size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# graph plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df=df['2010-01-01':'2018-09-01']\n",
    "\n",
    "# plot values from range\n",
    "fig, ax = plt.subplots(figsize=(15,7)) # setting up size\n",
    "df.Value.plot() # graph plot\n",
    "plt.ylabel('Value')\n",
    "plt.title('Monthly air revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stationarity test**\n",
    "\n",
    "We see our series are characterized by systematically repeating cycles. To gain high performance of predictions we need to make them stationary to build and apply models afterwards. \n",
    "Then, we start with series decomposition using seasonal component and Dickey-Fuller stationarity test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- plot decomposed series, display Dickey-Fuller criteria applying  .adfuller() function \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize(15,10))\n",
    "sm.tsa.seasonal_decompose(df.Value).plot()\n",
    "print \"Dickey-Fuller criteria: p=%f\" % sm.tsa.stattools.adfuller(df.Value)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high coefficient value for Dickey-Fuller criteria proves **non-stationarity** on 5% significance level.<br>\n",
    "The residuals and seasonality for decomposed series have a systematic character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dispersion stabilization**\n",
    "\n",
    "Additionally we are able to apply *Box-Cox power transformation* in order to reach higher dispersion stability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- create additional column of tranformed values using Box-Cox method\n",
    "- apply Dickey-Fuller test for transformed values \n",
    "\n",
    "\"\"\"\n",
    "df['Value_t'], lam=stats.boxcox(df['Value'])\n",
    "plt.figure(figsize(13,5))\n",
    "df['Value_t'].plot()\n",
    "plt.ylabel(u'FFE_amount-transformed')\n",
    "print \"lambda-optimum: %f\" % lam\n",
    "print \"Dickey-Fuller criteria: p=%f\" % sm.tsa.stattools.adfuller(df['Value_t'])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Differencing**\n",
    "\n",
    "Whereas the With Box-Cox transformation applied supposed to result stationary process based on Dickey-Fuller criteria, we still can observe non-ramdomized cycles in time series.<br>\n",
    "To avoid systematic flactuations, we can try differencing operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- applying 12 order differencing, we reduce data \n",
    "- however, this operation will improve the stationarity ratio \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df['diff'] = df.Value_t.diff(12)\n",
    "plt.figure(figsize(15,10))\n",
    "sm.tsa.seasonal_decompose(df['diff'][12:]).plot()\n",
    "print \"Dickey-Fuller criteria: p=%f\" % sm.tsa.stattools.adfuller(df['diff'][12:])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Dickey-Fuller criteria we can't prove stationarity, but we are able to make differencing for new series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff2'] = df['diff'].diff(1)\n",
    "pyplot.plot(df['diff2'])\n",
    "pyplot.show()\n",
    "print(\"Dickey-Fuller criteria: p=%f\" % sm.tsa.stattools.adfuller(df['diff2'][13:])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulted series can be categorized as stationary and described more like noise process, that can allow us to prepare model.<br>\n",
    "Before model fitting, represent the autocorrelation function (ACF) and partial autocorrelation function (PCF) plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AR model for lagged values estimation\n",
    "\n",
    "Let's fit Autoregressive model to establish the optimum number of lagged values.<br>\n",
    "We will use transformed values since only stationary series could be passed in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # check NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- shift 13 orders, since differencing was applied \n",
    "- autoregression package is already implemented in statmodels as AR()\n",
    "- order selection wil be based on AIC (Akaike criterion)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data=df['diff2'][13:]\n",
    "model=smt.AR(data)\n",
    "order=smt.AR(data).select_order(ic='aic', maxlag=25)\n",
    "\n",
    "print 'Best lag order = {}'.format(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given best lag order we are ready to visualize the autocorrelation/partial autocorrelation with ACF and PACF plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "\n",
    "plot_acf(df['diff2'][13:], ax=plt.gca(), lags=8)\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(df['diff2'][13:], ax=plt.gca(), lags=8)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACF plots display correlation between **series and its lags** and supposed to help in determining the **order of the MA (q) model.** <br>\n",
    "Partial autocorrelation plots (PACF), as the name suggests, display correlation between a variable and its lags that is not explained by previous lags. PACF plots are useful to set up the **order of the AR(p) model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the model fitting the train/test split is preffered. <br>\n",
    "For a test sample the last 15 observations (15 months, 14%) will be suitable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[:'2017-06-01']\n",
    "test=df['2017-07-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holt-Winter's model ###\n",
    "\n",
    "We can start from building Holt-Winter's model with exponental smoothing, adding trend component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt = Holt(np.asarray(train['Value'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1)\n",
    "test['Holt_linear'] = holt.forecast(len(test))\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(train['Value'], label='Train')\n",
    "plt.plot(test['Value'], label='Test')\n",
    "plt.plot(test['Holt_linear'], label='Holt_linear')\n",
    "plt.title('Holt linear trend')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA: parameters selection \n",
    "\n",
    "SARIMAX implenetation allows us to test range of parameters such as trend, seasonal component and noise for best model performance in the same way as \"grid-search\" does.\n",
    "\n",
    "The PACF graph represents 3 last lag value significantly different from zero. The value of $p$ could be chosen as $3$.<br>\n",
    "For $q$ value ACF represnts the first lag only as a considerable non-zero value, but in order to select the best from the range of models, its possible to fit SARIMAX with larger value, for instance, q from range(0,3). \n",
    "\n",
    "Seasonal component $D=1$ and difference parameter $d=1$. <br>\n",
    "Parameters Q and P will be selected based on best model from range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- since we need to fit model with all possible combinations\n",
    "we use product of parameters lists \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "P = range(0, 2)\n",
    "Q = range(0, 2)\n",
    "p = range(0, 3)\n",
    "q = range(0, 3)\n",
    "\n",
    "a = list(itertools.product(p, Q, p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- will add results of modeling to list based on AIC criterion \n",
    "\n",
    "\"\"\"\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for param in a:\n",
    "    try:\n",
    "        model=sm.tsa.statespace.SARIMAX(train.Value_t, order=(param[2], 1, param[3]), \n",
    "                                        seasonal_order=(param[0], 1, param[1], 12)).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('wrong parameters:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    \n",
    "warnings.filterwarnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ljung-Box criteria testifies that residuals are not autocorrelated with high significance level. <br>\n",
    "Autocorrelation plot presents the only outlier, that was not considered by model. In general, resuduals are converged around zero. Considerable difference is not orbserved on seasonal lags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- .plot_acf() to visualize the residuals partial autocorrelation for best model \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize(13,6))\n",
    "plt.subplot(211)\n",
    "best_model.resid[1:].plot()\n",
    "plt.ylabel(u'Residuals')\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "sm.graphics.tsa.plot_acf(best_model.resid[13:].values.squeeze(), lags=8, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student citeria does not reject the hypothesis of unbiased estimation, while Dickey-Fuller rejects the hypothesis of non-stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ttest_1samp for student criterion \n",
    "print \"Student criteria: p=%f\" % stats.ttest_1samp(best_model.resid[13:], 0)[1]\n",
    "print \"Dickey-Fuller criteria: p=%f\" % sm.tsa.stattools.adfuller(best_model.resid[13:])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the reverse procudere for Box-Cox transformation below, applying to train sample.<br>\n",
    "Then, we will plot train predictions, overlaped by true values to compare the modelling result with expected series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- function will return transformation based on given lambda:\n",
    "- exp transformation for lambda=0;\n",
    "- inverse log transformation if lambda<>0 \n",
    "\n",
    "\"\"\"\n",
    "def invboxcox(y,lam):\n",
    "    if lam == 0:\n",
    "        return(np.exp(y))\n",
    "    else:\n",
    "        return(np.exp(np.log(lam*y+1)/lam))\n",
    "\n",
    "train['Value_new'] = invboxcox(best_model.fittedvalues, lam)\n",
    "plt.figure(figsize(15,7))\n",
    "train.Value.plot()\n",
    "train.Value_new[13:].plot(color='r')\n",
    "plt.ylabel('Value')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the next step we evaluate predictions on test and plot result combind with train data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- make predictions, inversely transform and add to data frame\n",
    "- combine historical values with forecasted and display on graph \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "l=invboxcox(best_model.predict(start=89, end=120), lam)\n",
    "l=l.to_frame()\n",
    "l=l.rename(columns={0: 'Forecast'})\n",
    "test=test.rename(columns={\"Value\": 'Test_value'})\n",
    "\n",
    "df2=train[['Value']]\n",
    "# concat train and forecast frames for plotting\n",
    "df2 = pd.concat([df2, l])\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(df2['Value'], 'b-')\n",
    "plt.plot(l['Forecast'], 'r-')\n",
    "plt.legend(); plt.xlabel('Date'); plt.ylabel('Value')\n",
    "plt.title('Air Revenue (train sample) with Forecasted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions follow the shape of series, repeating the cycles over the months.<br>\n",
    "To prepare chart in more interactive way we can visualize series with plotly library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- combine true  data and forcasted values in one figure \n",
    "- plot figure inside notebook with connection mode on \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "data1 = go.Scatter(\n",
    "          x=df.index,\n",
    "          y=df2['Value'],\n",
    "    name='True Value')\n",
    "\n",
    "data2 = go.Scatter(\n",
    "          x=l.index,\n",
    "          y=l['Forecast'],\n",
    "name='Forecast Value')\n",
    "\n",
    "data= [data1, data2]\n",
    "layout = {'title': 'Air Revenue (train) with Forecasted'}\n",
    "fig=go.Figure(data=data, layout=layout)\n",
    "\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecat Accuracy Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate model performace, we are going to estimate mean squared and mean absolute errors and plot forecasted values over the test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- display forecatsted and test values by red and green respectively \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(df2['Value'], 'b-')\n",
    "plt.plot(l['Forecast'][:'2018-11-05'], 'r-')\n",
    "plt.plot(test['Test_value'], 'g-')\n",
    "plt.legend(); plt.xlabel('Date'); plt.ylabel('Air Revenue')\n",
    "plt.title('Air Revenue: entire samle with Forecasted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate MSE and MAE on test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared value on test \n",
    "mse = ((l['2017-07-01':'2018-09-01']['Forecast'] - test['2017-07-01':'2018-09-01']['Test_value']) ** 2).mean()\n",
    "print('The Mean Squared Error of forecasts is {}'.format(round(mse, 2)))\n",
    "\n",
    "# mean absolute value on test \n",
    "mae = (l['2017-07-01':'2018-09-01']['Forecast'] - test['2017-07-01':'2018-09-01']['Test_value']).mean()\n",
    "print('The Mean Absolute Error of forecasts is {}'.format(round(mae, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *References:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.coursera.org/lecture/data-analysis-applications/vriemiennyie-riady-EjNEV <br>\n",
    "http://www.iosrjournals.org/iosr-jm/papers/vol1-issue3/C0131020.pdf<br>\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.ar_model.AR.select_order.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
